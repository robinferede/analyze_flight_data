{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Drone Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=45, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=45, out_features=45, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=45, out_features=3, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "input: tensor([0.0587, 0.5041, 0.5323, 0.0903, 0.8781, 0.9567, 0.6165, 0.7778, 0.8789,\n",
      "        0.5550, 0.0788])\n",
      "output: tensor([0.5553, 0.4796, 0.7651], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_606307/295981442.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('ThrustDragModel.pth'))  # Load the saved state_dict\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from analyze import *\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(11, 45, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(45, 45, bias=True),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(45, 3, bias=True),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# load ThrustDragModel.pth\n",
    "model.load_state_dict(torch.load('ThrustDragModel.pth'))  # Load the saved state_dict\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "print(model)\n",
    "\n",
    "# test model with random input\n",
    "input = torch.rand(11)\n",
    "output = model(input)\n",
    "print('input:', input)\n",
    "print('output:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04469422 -0.13402294 -0.17259765]\n"
     ]
    }
   ],
   "source": [
    "def get_modeled_acceleration(vbx, vby, vbz, omega0, omega1, omega2, omega3, p, q, r, ax, ay, az):\n",
    "    # input tensor\n",
    "    input_tensor = torch.tensor([az, p, q, r, vbx, vby, vbz, omega0, omega1, omega2, omega3], dtype=torch.float32)\n",
    "    # normalize inputs\n",
    "    input_tensor[0] = input_tensor[0] / 50          # az\n",
    "    input_tensor[1:4] = input_tensor[1:4] / 10      # p, q, r\n",
    "    input_tensor[4:7] = input_tensor[4:7] / 10      # vbx, vby, vbz\n",
    "    input_tensor[7:11] = input_tensor[7:11] / 3000  # omega0, omega1, omega2, omega3\n",
    "    # get the output tensor\n",
    "    output_tensor = model(input_tensor)\n",
    "    # the output is: z-bias, k_x, k_y\n",
    "    z_bias_scaled = output_tensor[0]\n",
    "    z_bias = (2*z_bias_scaled - 1)*2\n",
    "    k_x = output_tensor[1]\n",
    "    k_y = output_tensor[2]\n",
    "    # get modeled acceleration\n",
    "    ax_model = -k_x * vbx\n",
    "    ay_model = -k_y * vby\n",
    "    az_model = az + z_bias\n",
    "    # return ax_model, ay_model, az_model as np.array\n",
    "    output = np.array([ax_model.item(), ay_model.item(), az_model.item()])\n",
    "    return output\n",
    "\n",
    "# test get_modeled_acceleration with random input\n",
    "print(get_modeled_acceleration(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=11, out_features=45, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=45, out_features=45, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=45, out_features=3, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# convert the model into nn.Sequential\n",
    "network = model\n",
    "\n",
    "print('NETWORK:')\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated c_code/drone_model.c\n",
      "Generated c_code/drone_model.h\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# remove the c_code folder and all of its contents\n",
    "subprocess.call('rm -rf c_code', shell=True)\n",
    "# create a new c_code folder\n",
    "subprocess.call('mkdir c_code', shell=True)\n",
    "\n",
    "output_folder = \"c_code\"\n",
    "\n",
    "# Generate the C file and the header file inside the \"c_code\" folder\n",
    "source_file_path = os.path.join(output_folder, \"drone_model.c\")\n",
    "header_file_path = os.path.join(output_folder, \"drone_model.h\")\n",
    "\n",
    "# np.float32 to str\n",
    "float_to_str = lambda x: str(float(x))\n",
    "\n",
    "# Generate the C file\n",
    "with open(source_file_path, \"w\") as file:\n",
    "    file.write('#include \"drone_model.h\"\\n')\n",
    "    file.write(\"#include <stdio.h>\\n\")\n",
    "    file.write(\"#include <math.h>\\n\\n\")\n",
    "\n",
    "    # modeled acceleration set to zero\n",
    "    file.write(\"float ax_modeled = 0;\\n\")\n",
    "    file.write(\"float ay_modeled = 0;\\n\")\n",
    "    file.write(\"float az_modeled = 0;\\n\\n\")\n",
    "    \n",
    "    # Define weights and biases as global constant float arrays\n",
    "    i = 1\n",
    "    for layer in network:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            weights_layer = layer.weight.data.cpu().numpy()\n",
    "            biases_layer = layer.bias.data.cpu().numpy()\n",
    "\n",
    "            file.write(f\"const float weights_fc{i}[] = {{\\n\")\n",
    "            file.write(\",\\n\".join([\", \".join(map(float_to_str, row)) for row in weights_layer]))\n",
    "            file.write(\"\\n};\\n\\n\")\n",
    "\n",
    "            file.write(f\"const float biases_fc{i}[] = {{\\n\")\n",
    "            file.write(\", \".join(map(float_to_str, biases_layer)))\n",
    "            file.write(\"\\n};\\n\\n\")\n",
    "\n",
    "            i+=1\n",
    "\n",
    "    # LINEAR LAYER\n",
    "    file.write(\"void nn_linear(const float* weights, const float* biases, const float* input, int in_features, int out_features, float* output) {\\n\")\n",
    "    file.write(\"    for (int i = 0; i < out_features; ++i) {\\n\")\n",
    "    file.write(\"        float neuron = biases[i];\\n\")\n",
    "    file.write(\"        for (int j = 0; j < in_features; ++j) {\\n\")\n",
    "    file.write(\"            neuron += input[j] * weights[i * in_features + j];\\n\")\n",
    "    file.write(\"        }\\n\")\n",
    "    file.write(\"        output[i] = neuron;\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"}\\n\\n\")\n",
    "\n",
    "    # RELU LAYER\n",
    "    file.write(\"void nn_relu(float* input, int size) {\\n\")\n",
    "    file.write(\"    for (int i = 0; i < size; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = fmaxf(0, input[i]);\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"}\\n\\n\")\n",
    "\n",
    "    # TANH LAYER\n",
    "    file.write(\"void nn_tanh(float* input, int size) {\\n\")\n",
    "    file.write(\"    for (int i = 0; i < size; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = tanh(input[i]);\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"}\\n\\n\")\n",
    "    \n",
    "    # SIGMOID LAYER\n",
    "    file.write(\"void nn_sigmoid(float* input, int size) {\\n\")\n",
    "    file.write(\"    for (int i = 0; i < size; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = 1 / (1 + exp(-input[i]));\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"}\\n\\n\")\n",
    "\n",
    "    # FORWARD FUNCTION\n",
    "    file.write(\"void nn_forward(const float* input, float* output) {\\n\")\n",
    "    layer_size = network[0].out_features\n",
    "    num_layers = sum(isinstance(layer, nn.Linear) for layer in network)\n",
    "    i=0\n",
    "    input_array = \"input\"\n",
    "    for layer in network:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            i+=1\n",
    "            if i<num_layers:\n",
    "                file.write(f\"    float fc{i}_output[{layer.out_features}];\\n\")\n",
    "                file.write(f\"    nn_linear(weights_fc{i}, biases_fc{i}, {input_array}, {layer.in_features}, {layer.out_features}, fc{i}_output);\\n\")\n",
    "                input_array = f\"fc{i}_output\"\n",
    "            else:\n",
    "                file.write(f\"    nn_linear(weights_fc{i}, biases_fc{i}, {input_array}, {layer.in_features}, {layer.out_features}, output);\\n\")\n",
    "                input_array = \"output\"\n",
    "            layer_size = layer.out_features\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            file.write(f\"    nn_relu({input_array}, {layer_size});\\n\")\n",
    "        elif isinstance(layer, nn.Tanh):\n",
    "            file.write(f\"    nn_tanh({input_array}, {layer_size});\\n\")\n",
    "        elif isinstance(layer, nn.Sigmoid):\n",
    "            file.write(f\"    nn_sigmoid({input_array}, {layer_size});\\n\")\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported layer: {layer}\")\n",
    "    file.write(\"}\\n\")\n",
    "    \n",
    "    # COMPUTE MODELED ACCELERATION FUNCTION\n",
    "    file.write(\"void compute_modeled_acceleration(float vbx, float vby, float vbz,\\n\")\n",
    "    file.write(\"                          float omega0, float omega1, float omega2, float omega3,\\n\")\n",
    "    file.write(\"                          float p, float q, float r, float ax_measured, float ay_measured, float az_measured\\n\")\n",
    "    file.write(\") {\\n\")\n",
    "    file.write(\"    // let compiler know which variables are not used \\n\")\n",
    "    file.write(\"    (void) ax_measured;\\n\")\n",
    "    file.write(\"    (void) ay_measured;\\n\\n\")\n",
    "    file.write(\"    // neural network input\\n\")\n",
    "    file.write(\"    float input[] = {az_measured, p, q, r, vbx, vby, vbz, omega0, omega1, omega2, omega3};\\n\")\n",
    "    file.write(\"    // normalize inputs\\n\")\n",
    "    file.write(\"    input[0] = input[0] / 50;           // az\\n\")\n",
    "    file.write(\"    for (int i = 1; i < 4; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = input[i] / 10;       // p, q, r\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"    for (int i = 4; i < 7; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = input[i] / 10;       // vbx, vby, vbz\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"    for (int i = 7; i < 11; ++i) {\\n\")\n",
    "    file.write(\"        input[i] = input[i] / 3000;     // omega0, omega1, omega2, omega3\\n\")\n",
    "    file.write(\"    }\\n\")\n",
    "    file.write(\"    // neural network output\\n\")\n",
    "    file.write(\"    float output[3];\\n\")\n",
    "    file.write(\"    // run the neural network\\n\")\n",
    "    file.write(\"    nn_forward(input, output);\\n\")\n",
    "    file.write(\"    // process the output\\n\")\n",
    "    file.write(\"    float z_bias_scaled = output[0];\\n\")\n",
    "    file.write(\"    float z_bias = (2*z_bias_scaled - 1)*2;\\n\")\n",
    "    file.write(\"    float k_x = output[1];\\n\")\n",
    "    file.write(\"    float k_y = output[2];\\n\")\n",
    "    file.write(\"    // get modeled acceleration\\n\")\n",
    "    file.write(\"    ax_modeled = -k_x * vbx;\\n\")\n",
    "    file.write(\"    ay_modeled = -k_y * vby;\\n\")\n",
    "    file.write(\"    az_modeled = az_measured + z_bias;\\n\")\n",
    "    file.write(\"}\\n\\n\")\n",
    "    \n",
    "    # GET MODELED ACCELERATION FUNCTION\n",
    "    file.write(\"void get_modeled_acceleration(float *ax, float *ay, float *az) {\\n\")\n",
    "    file.write(\"    *ax = ax_modeled;\\n\")\n",
    "    file.write(\"    *ay = ay_modeled;\\n\")\n",
    "    file.write(\"    *az = az_modeled;\\n\")\n",
    "    file.write(\"}\\n\") \n",
    "\n",
    "# Generate the header file\n",
    "with open(header_file_path, \"w\") as header_file:\n",
    "    header_file.write(\"#ifndef DRONE_MODEL_H\\n\")\n",
    "    header_file.write(\"#define DRONE_MODEL_H\\n\\n\")\n",
    "    header_file.write(\"void compute_modeled_acceleration(float vbx, float vby, float vbz,\\n\")\n",
    "    header_file.write(\"                          float omega0, float omega1, float omega2, float omega3,\\n\")\n",
    "    header_file.write(\"                          float p, float q, float r, float ax_measured, float ay_measured, float az_measured\\n\")\n",
    "    header_file.write(\");\\n\\n\")\n",
    "    header_file.write(\"void get_modeled_acceleration(float *ax, float *ay, float *az);\\n\\n\")\n",
    "    header_file.write(\"#endif // DRONE_MODEL_H\\n\")\n",
    "\n",
    "\n",
    "# Print the generated files\n",
    "# Print the generated files\n",
    "print(f\"Generated {source_file_path}\")\n",
    "print(f\"Generated {header_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the C code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04469422 -0.13402294 -0.17259765]\n",
      "(-0.051831867545843124, -0.17743301391601562, -0.25316333770751953)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(ctypes)\n",
    "\n",
    "# https://cu7ious.medium.com/how-to-use-dynamic-libraries-in-c-46a0f9b98270\n",
    "path = os.path.abspath('c_code')\n",
    "# Create object files\n",
    "subprocess.call('gcc -fPIC -c *.c', shell=True, cwd=path)\n",
    "# Create library\n",
    "subprocess.call('gcc -shared -Wl,-soname,libtools.so -o libtools.so *.o', shell=True, cwd=path)\n",
    "# Remove object files\n",
    "subprocess.call('rm *.o', shell=True, cwd=path)\n",
    "\n",
    "lib_path = os.path.abspath(\"c_code/libtools.so\")\n",
    "fun = ctypes.CDLL(lib_path)\n",
    "\n",
    "# define argument types \n",
    "fun.compute_modeled_acceleration.argtypes = [ctypes.c_float]*13\n",
    "fun.get_modeled_acceleration.argtypes = [ctypes.POINTER(ctypes.c_float)]*3\n",
    "\n",
    "# get python function to call the C function\n",
    "def get_modeled_acceleration_c_code(vbx, vby, vbz, omega0, omega1, omega2, omega3, p, q, r, ax, ay, az):\n",
    "    fun.compute_modeled_acceleration(vbx, vby, vbz, omega0, omega1, omega2, omega3, p, q, r, ax, ay, az)\n",
    "    ax = ctypes.c_float()\n",
    "    ay = ctypes.c_float()\n",
    "    az = ctypes.c_float()\n",
    "    fun.get_modeled_acceleration(ctypes.byref(ax), ctypes.byref(ay), ctypes.byref(az))\n",
    "    return ax.value, ay.value, az.value\n",
    "\n",
    "# check if get_modeled_acceleration_c_code gives the same result as get_modeled_acceleration\n",
    "print(get_modeled_acceleration(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 0, 0))\n",
    "print(get_modeled_acceleration_c_code(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_flight_data('flight_data/Okt25_Dummy_fig8_normal.csv')\n",
    "data = trim_nn_active(data)\n",
    "\n",
    "# get az, p, q, r, vbx, vby, vbz, omega0, omega1, omega2, omega3\n",
    "model_input = np.array([\n",
    "    data[key] for key in ['vbx', 'vby', 'vbz', 'omega[0]', 'omega[1]', 'omega[2]', 'omega[3]', 'p', 'q', 'r', 'ax', 'ay', 'az']\n",
    "]).T\n",
    "\n",
    "# get modeled acceleration\n",
    "modeled_acceleration = np.array([\n",
    "    get_modeled_acceleration(*input) for input in model_input\n",
    "])\n",
    "\n",
    "# get modeled acceleration with C code\n",
    "modeled_acceleration_c_code = np.array([\n",
    "    get_modeled_acceleration_c_code(*input) for input in model_input\n",
    "])\n",
    "\n",
    "# plot acceleration and modeled acceleration\n",
    "plt.plot(data['t'], data['ax'], label='ax')\n",
    "plt.plot(data['t'], modeled_acceleration[:, 0], label='ax_model')\n",
    "plt.plot(data['t'], modeled_acceleration_c_code[:, 0], label='ax_model_c_code')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(data['t'], data['ay'], label='ay')\n",
    "plt.plot(data['t'], modeled_acceleration[:, 1], label='ay_model')\n",
    "plt.plot(data['t'], modeled_acceleration_c_code[:, 1], label='ay_model_c_code')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(data['t'], data['az'], label='az')\n",
    "plt.plot(data['t'], modeled_acceleration[:, 2], label='az_model')\n",
    "plt.plot(data['t'], modeled_acceleration_c_code[:, 2], label='az_model_c_code')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
